{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOfA7vlChz5gjp9977VbmAc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nagaharikathota/dl/blob/main/DL_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMw5K1UR-xvp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.python import keras\n",
        "from tensorflow.python.keras import utils\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.utils import to_categorical\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, InputLayer\n",
        "import imageio # To read images\n",
        "from PIL import Image # For image resizing\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip agedetectiontest.zip\n",
        "!unzip agedetectiontrain.zip"
      ],
      "metadata": {
        "id": "ux1LTJq5_HFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/train.csv')\n",
        "test = pd.read_csv('/content/test.csv')"
      ],
      "metadata": {
        "id": "pkZBJoNqBOyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(3)\n",
        "idx = np.random.choice(train.index)\n",
        "img_name = train.ID[idx]\n",
        "img = imageio.imread(os.path.join('/content/Train', img_name))\n",
        "print('Age group:', train.Class[idx])\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4yHi3oBCB1MZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let us reshape and transform the training data first, as shown below:\n",
        "temp = []\n",
        "for img_name in train.ID:\n",
        "    img_path = os.path.join('Train', img_name)\n",
        "    img = imageio.imread(img_path)\n",
        "    img = np.array(Image.fromarray(img).resize((32, 32))).astype('float32')\n",
        "    temp.append(img)\n",
        "train_x = np.stack(temp)"
      ],
      "metadata": {
        "id": "XIB1kBPkFULR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Next, let us reshape and transform the testing data, as shown below:\n",
        "temp = []\n",
        "for img_name in test.ID:\n",
        "    img_path = os.path.join('Test', img_name)\n",
        "    img = imageio.imread(img_path)\n",
        "    img = np.array(Image.fromarray(img).resize((32, 32))).astype('float32')\n",
        "    temp.append(img)\n",
        "test_x = np.stack(temp)"
      ],
      "metadata": {
        "id": "fGEK0vtXFbXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing the images\n",
        "train_x = train_x / 255.\n",
        "test_x = test_x / 255.\n"
      ],
      "metadata": {
        "id": "TYffXvn-FfNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding the categorical variable to numeric\n",
        "lb = LabelEncoder()\n",
        "train_y = lb.fit_transform(train.Class)\n",
        "train_y = utils.to_categorical(train_y)"
      ],
      "metadata": {
        "id": "dTnZtF_RFiwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specifying all the parameters we will be using in our network\n",
        "input_num_units = (32, 32, 3)\n",
        "hidden_num_units = 500\n",
        "output_num_units = 3\n",
        "epochs = 5\n",
        "batch_size = 128"
      ],
      "metadata": {
        "id": "eiAWWFoRFmcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Next, let us define a network with one input layer, one hidden layer, and one output layer, as shown below:\n",
        "model = Sequential([\n",
        "  InputLayer(input_shape=input_num_units),\n",
        "  Flatten(),\n",
        "  Dense(units=hidden_num_units, activation='relu'),\n",
        "  Dense(units=output_num_units, activation='softmax'),\n",
        "])"
      ],
      "metadata": {
        "id": "8VXPXzoZFqBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "28BDxSTRFvvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling and Training Network\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "dQp8WVU8Fzuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now, let us build the model, using the fit() method:\n",
        "model.fit(train_x, train_y, batch_size=batch_size, epochs=epochs, verbose=1)\n"
      ],
      "metadata": {
        "id": "qP9zVZEAF2yW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#The following code considers 20 percent of the training data as validation data set:\n",
        "# Training model along with validation data\n",
        "model.fit(train_x, train_y, batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.2)\n"
      ],
      "metadata": {
        "id": "rgsLC_GnF6VF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting and importing the result in a csv file\n",
        "#pred = model.predict_classes(test_x)\n",
        "pred = np.argmax(model.predict(test_x),axis=1)\n",
        "pred = lb.inverse_transform(pred)\n",
        "test['Class'] = pred\n",
        "test.to_csv('out.csv', index=False)\n"
      ],
      "metadata": {
        "id": "u-fP9CmbF_uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visual Inspection of predictions\n",
        "idx = 300\n",
        "img_name = test.ID[idx]\n",
        "img = imageio.imread(os.path.join('/content/Test', img_name))\n",
        "plt.imshow(np.array(Image.fromarray(img).resize((128, 128))))\n",
        "pred = np.argmax(model.predict(test_x),axis=1)\n",
        "#pred = model.predict_classes(test_x)\n",
        "print('Original:', train.Class[idx], 'Predicted:', lb.inverse_transform([pred[idx]]))\n"
      ],
      "metadata": {
        "id": "ZWoEzxz2GEJm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}